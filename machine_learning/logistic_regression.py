"""LOGISTIC Regression and the ROC CurveKeys:- Used for classification problems - This model calculates the probability p (that an observation belongs to a binary class)- It produces a linear decision boundary… for example we set that if p were equal to 0.4, then the value of the predictions is 0 and if it were more that 0.5 then we set 1…THIS IS A LINEAR MODEL"""# Codefrom sklearn.linear_model import LogisticRegressionfrom sklearn.model_selections import train_test_scplitmodel = LogisticRegression()X = y = X_train, x_test, y_train, y_test = train_test_scplit(X, y, test_size = 0.3, random_state = 42)model.fit(X_train, y_train)y_pred = model.predict(X_test)'''Predicting Probabilities of each Instance (Row) - Yes or No (Classes)Key:Instance =  Cada fila es una instancia, o una observación.We can predict probabilities of each instance (de cada fila) belonging to a class by calling logistic regression's predict_proba function and passing the test features.Returns: It returns a 2 dimensional array with probabilities for both classes (Yes or No, Churn or NO churn, etc.).********Regresa una matriz de tamaño: n_muestras x 2Donde las columnas son:columna 0: probabilidad de clase 0columna 1: probabilidad de clase 1And the rows are the observations, the X_test´s elements whose probability we compute respectively.That is why we slice the second column, representing ONLY the positive class probabilities, and store the results as y_pred_probs.2. Then, we take the first value corresponding to the first observation or instancethis value is the value that the model predicted, a probabilityfor example point-zero-eight-nine and this is the probability that the first observation has churned. With threshold equals to 5.'''# Codey_pred_probs = model.predict_proba(X_test)[:,1]print(y_pred_probs[0])#################################### THRESHOLDS# ROC - CURVE###################################'''Of course, the default probability threshold for logistic regression in scikit-learn is zero-point-five.We can use a receiver operating characteristic, or ROC curve, to VISUALIZE how different thresholds affect true positive and false positive rates. - If the threshold equals one, the model predicts zero for all data, which means that both true and false positive rates are zero- If we vary the threshold, we get a series of different false positive and true positive rates.    These, FP, TP belongs to the confusion matrix second column.    Remember that in the diagonal entries of the matrix are the TRUE values, where the model was right. A line plot of the thresholds helps to visualize the trend...'''# Codefrom sklearn.metrics import roc_curvefpr, tpr, thresholds = roc_surve(y_test, y_pred_probs)# We unpack the results into three variables: # false positive rate, FPR# true positive rate, TPR# Thresholds. """We can then plot a dotted line from zero to one, along with the FPR and TPR; to produce a figure such as this. This looks great, but how do we quantify the model's performance based on this plot?"""plt.plot([0,1], [0,1], 'k--')plt.plot(fpr, tpr)plt.xlabel('False Positive Rate')plt.ylabel('True Positive Rate')plt.title('Logistic Regression ROC Curve')plt.show()# If we have a model with one for true positive rate and zero for false positive rate, this would be the perfect model. 